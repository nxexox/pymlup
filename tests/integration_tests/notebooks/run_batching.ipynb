{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "356a372b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import mlup\n",
    "from mlup import constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "501cf3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel:\n",
    "    def predict(self, X):\n",
    "        return X\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58f2bca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "up = mlup.UP(\n",
    "    ml_model=model, \n",
    "    conf=mlup.Config(\n",
    "        data_transformer_for_predict=constants.ModelDataTransformerType.SRC_TYPES,\n",
    "        data_transformer_for_predicted=constants.ModelDataTransformerType.SRC_TYPES,\n",
    "        mode=constants.WebAppArchitecture.batching,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8f0b696",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[84826][140704293254912] [2023-08-15 17:36:08.430] INFO - Load model with settings: \n",
      "    name=MyFirstMLupModel\n",
      "    version=1.0.0.0\n",
      "    type=sklearn\n",
      "    columns=None\n",
      "    predict_method_name=predict\n",
      "    auto_detect_predict_params=True\n",
      "    storage_type=mlup.ml.storage.memory.MemoryStorage\n",
      "    binarization_type=mlup.ml.binarization.pickle.PickleBinarizer\n",
      "    use_thread_loop=True\n",
      "    max_thread_loop_workers=None\n",
      "    data_type_for_predict=mlup.ml.data_transformers.src_data_transformer.SrcDataTransformer\n",
      "    data_type_for_predicted=mlup.ml.data_transformers.src_data_transformer.SrcDataTransformer\n",
      "[84826][140704293254912] [2023-08-15 17:36:08.457] INFO - Create storage <class 'mlup.ml.storage.memory.MemoryStorage'>.\n",
      "[84826][140704293254912] [2023-08-15 17:36:08.458] INFO - Time to load binary model to memory: 0.000.\n",
      "[84826][140704293254912] [2023-08-15 17:36:08.519] INFO - Auto analyzing arguments in <bound method MyModel.predict of <__main__.MyModel object at 0x10eea4040>>.\n",
      "[84826][140704293254912] [2023-08-15 17:36:08.520] INFO - Found X param in model params. Set List type\n",
      "[84826][140704293254912] [2023-08-15 17:36:08.521] INFO - Time to load model settings: 0.003.\n"
     ]
    }
   ],
   "source": [
    "up.ml.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42f95f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[84826][140704293254912] [2023-08-15 17:36:14.444] INFO - The model work  0.002.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "up.predict(X=[1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fc05886",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[84826][140704293254912] [2023-08-15 17:36:15.974] INFO - Load Web application with settings:\n",
      "    host=0.0.0.0\n",
      "    port=8009\n",
      "    web_app_version=1.0.0.0\n",
      "    column_validation=False\n",
      "    custom_column_pydantic_model=None\n",
      "    mode=mlup.web.architecture.batching.BatchingSingleProcessArchitecture\n",
      "    max_queue_size=100\n",
      "    ttl_predicted_data=60\n",
      "    ttl_client_wait=30.0\n",
      "    min_batch_len=10\n",
      "    batch_worker_timeout=1.0\n",
      "    is_long_predict=False\n",
      "    debug=False\n",
      "    throttling_max_requests=None\n",
      "    throttling_max_request_len=None\n",
      "    timeout_for_shutdown_daemon=3.0\n",
      "    item_id_col_name=mlup_item_id\n",
      "[84826][140704293254912] [2023-08-15 17:36:15.989] INFO - Load mlup.web.architecture.batching.BatchingSingleProcessArchitecture web app architecture with params:\n",
      "    item_id_col_name=mlup_item_id\n",
      "    min_batch_len=10\n",
      "    max_queue_size=100\n",
      "    batch_worker_timeout=1.0\n",
      "    ttl_predicted_data=60\n",
      "    ttl_client_wait=30.0\n",
      "    is_long_predict=False\n",
      "[84826][140704293254912] [2023-08-15 17:36:15.991] INFO - Waiting start uvicorn proc with web app 30.0 seconds.\n",
      "INFO:     Started server process [84826]\n",
      "INFO:     Waiting for application startup.\n",
      "[84826][123145628471296] [2023-08-15 17:36:16.103] INFO - Running model in batching worker\n",
      "[84826][123145628471296] [2023-08-15 17:36:16.104] INFO - Start checking the batch queue...\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8009 (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "up.run_web_app(daemon=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab79bbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[84826][123145628471296] [2023-08-15 17:36:24.262] INFO - New request ef46b811-760f-4b9a-9345-cd6188307c95 put to queue.\n",
      "[84826][123145628471296] [2023-08-15 17:36:25.331] INFO - Batch handling started after 1.00 seconds for 1 requests\n",
      "[84826][123145628471296] [2023-08-15 17:36:25.332] INFO - Batch length 3.\n",
      "[84826][123145628471296] [2023-08-15 17:36:25.333] INFO - Predict ids in batch: ef46b811-760f-4b9a-9345-cd6188307c95\n",
      "[84826][123145628471296] [2023-08-15 17:36:25.334] INFO - Running predict for batch\n",
      "[84826][123145628471296] [2023-08-15 17:36:25.384] INFO - The model work  0.015.\n",
      "[84826][123145628471296] [2023-08-15 17:36:25.392] INFO - End predict for batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:61326 - \"POST /predict HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "resp = requests.post('http://0.0.0.0:8009/predict', json={'X': [1, 2, 3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bd4d260",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "[84826][123145628471296] [2023-08-15 17:36:53.293] INFO - Stop checking the batch queue...\n",
      "[84826][123145628471296] [2023-08-15 17:36:53.295] INFO - Batching worker stopped\n",
      "INFO:     Application shutdown complete.\n"
     ]
    }
   ],
   "source": [
    "up.stop_web_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29850e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predict_result': [1, 2, 3]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.json()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}