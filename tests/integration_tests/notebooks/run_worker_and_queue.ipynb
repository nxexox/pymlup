{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "356a372b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import mlup\n",
    "from mlup import constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "501cf3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel:\n",
    "    def predict(self, X):\n",
    "        return X\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58f2bca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "up = mlup.UP(\n",
    "    ml_model=model, \n",
    "    conf=mlup.Config(\n",
    "        data_transformer_for_predict=constants.ModelDataTransformerType.SRC_TYPES,\n",
    "        data_transformer_for_predicted=constants.ModelDataTransformerType.SRC_TYPES,\n",
    "        mode=constants.WebAppArchitecture.worker_and_queue,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8f0b696",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[84897][140704293254912] [2023-08-15 17:37:36.580] INFO - Load model with settings: \n",
      "    name=MyFirstMLupModel\n",
      "    version=1.0.0.0\n",
      "    type=sklearn\n",
      "    columns=None\n",
      "    predict_method_name=predict\n",
      "    auto_detect_predict_params=True\n",
      "    storage_type=mlup.ml.storage.memory.MemoryStorage\n",
      "    binarization_type=mlup.ml.binarization.pickle.PickleBinarizer\n",
      "    use_thread_loop=True\n",
      "    max_thread_loop_workers=None\n",
      "    data_type_for_predict=mlup.ml.data_transformers.src_data_transformer.SrcDataTransformer\n",
      "    data_type_for_predicted=mlup.ml.data_transformers.src_data_transformer.SrcDataTransformer\n",
      "[84897][140704293254912] [2023-08-15 17:37:36.596] INFO - Create storage <class 'mlup.ml.storage.memory.MemoryStorage'>.\n",
      "[84897][140704293254912] [2023-08-15 17:37:36.597] INFO - Time to load binary model to memory: 0.000.\n",
      "[84897][140704293254912] [2023-08-15 17:37:36.647] INFO - Auto analyzing arguments in <bound method MyModel.predict of <__main__.MyModel object at 0x10dea76a0>>.\n",
      "[84897][140704293254912] [2023-08-15 17:37:36.648] INFO - Found X param in model params. Set List type\n",
      "[84897][140704293254912] [2023-08-15 17:37:36.649] INFO - Time to load model settings: 0.002.\n"
     ]
    }
   ],
   "source": [
    "up.ml.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42f95f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[84897][140704293254912] [2023-08-15 17:37:38.093] INFO - The model work  0.001.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "up.predict(X=[1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fc05886",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[84897][140704293254912] [2023-08-15 17:37:38.940] INFO - Load Web application with settings:\n",
      "    host=0.0.0.0\n",
      "    port=8009\n",
      "    web_app_version=1.0.0.0\n",
      "    column_validation=False\n",
      "    custom_column_pydantic_model=None\n",
      "    mode=mlup.web.architecture.worker_and_queue.WorkerAndQueueArchitecture\n",
      "    max_queue_size=100\n",
      "    ttl_predicted_data=60\n",
      "    ttl_client_wait=30.0\n",
      "    min_batch_len=10\n",
      "    batch_worker_timeout=1.0\n",
      "    is_long_predict=False\n",
      "    debug=False\n",
      "    throttling_max_requests=None\n",
      "    throttling_max_request_len=None\n",
      "    timeout_for_shutdown_daemon=3.0\n",
      "    item_id_col_name=mlup_item_id\n",
      "[84897][140704293254912] [2023-08-15 17:37:38.954] INFO - Load mlup.web.architecture.worker_and_queue.WorkerAndQueueArchitecture web app architecture with params:\n",
      "    item_id_col_name=mlup_item_id\n",
      "    max_queue_size=100\n",
      "    ttl_predicted_data=60\n",
      "    is_long_predict=False\n",
      "    ttl_client_wait=30.0\n",
      "[84897][140704293254912] [2023-08-15 17:37:38.961] INFO - Waiting start uvicorn proc with web app 30.0 seconds.\n",
      "INFO:     Started server process [84897]\n",
      "INFO:     Waiting for application startup.\n",
      "[84897][123145504481280] [2023-08-15 17:37:39.025] INFO - Running model in worker\n",
      "[84897][123145504481280] [2023-08-15 17:37:39.029] INFO - Start checking the queue...\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8009 (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "up.run_web_app(daemon=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab79bbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[84897][123145504481280] [2023-08-15 17:37:42.237] INFO - New request cea5c7cf-1f1f-4075-9c06-5c6f73e4cce9 put to queue.\n",
      "[84897][123145504481280] [2023-08-15 17:37:42.267] INFO - Running predict for cea5c7cf-1f1f-4075-9c06-5c6f73e4cce9\n",
      "[84897][123145504481280] [2023-08-15 17:37:42.271] INFO - The model work  0.002.\n",
      "[84897][123145504481280] [2023-08-15 17:37:42.279] INFO - End predict for cea5c7cf-1f1f-4075-9c06-5c6f73e4cce9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:61412 - \"POST /predict HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "resp = requests.post('http://0.0.0.0:8009/predict', json={'X': [1, 2, 3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bd4d260",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "[84897][123145504481280] [2023-08-15 17:37:51.967] INFO - Stop checking the queue...\n",
      "[84897][123145504481280] [2023-08-15 17:37:51.970] INFO - Worker stopped\n",
      "INFO:     Application shutdown complete.\n"
     ]
    }
   ],
   "source": [
    "up.stop_web_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29850e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predict_result': [1, 2, 3]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.json()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}